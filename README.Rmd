
---
title: "README"
output:
github_document:
pandoc_args: ["--wrap=none"]
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Load necessary libraries
library(httr)  # For making authenticated requests
library(utils) # For downloading and unzipping

# Define the Kaggle dataset URL (Make sure your API token is set up)
url <- "https://www.kaggle.com/api/v1/datasets/download/fratzcan/usa-house-prices"

# Define download destination
destfile <- "./usa-house-prices.zip"

# Download the file
download.file(url, destfile, mode = "wb")

# Extract the ZIP file
unzip(destfile, exdir = "./usa-house-prices")

# List the extracted files to check the exact CSV file name
list.files("./usa-house-prices")

# Read the CSV file (Replace with the actual extracted filename)
housing_data <- read.csv("./usa-house-prices/USA Housing Dataset.csv")

```

# Understanding the Data
## When was the data acquired?
Based on our analysis, the data appears to be from **2014**. 
Specifically, all date entries in the dataset follow the `"2014-05-09"` format. 
This suggests the dataset represents a **snapshot** of the housing market from 
May to July 2014, rather than a **time series spanning multiple years**.
```{r}
# Checking unique dates in the dataset by inspecting the date column
unique(housing_data$date)
```

## Where was the data acquired?
The dataset covers housing properties in the state of **Washington (WA)**, 
primarily focusing on the **Seattle metropolitan area and surrounding regions**. 
```{r}
# Viewing unique city names
unique(housing_data$city)
```

## How was the data acquired?
The dataset does not explicitly state its source, but based on its structured 
format and detailed attributes, it appears to be compiled from:
1. **Real estate transaction records**
2. **Multiple Listing Service (MLS) data**

## What are the attributes of this dataset?
The date of transaction, sale price, number of bedrooms and bathrooms, interior 
square footage, land square footage, number of floors, whether or not it is a 
waterfront property, quality of its view (rating), condition of house (rating), 
square footage above ground level, square footage of basement, year house was 
built, year of last renovation, and address details including street name, city, 
state, zip code, and country. 
```{r}
# Checking structure of dataset
str(housing_data)
```

## What type of data do these attributes hold?
Data Type	Attributes
**Nominal** (Categorical, Unordered): street, city, state, zip code, country
**Ordinal** (Categorical, Ordered): view, condition, waterfront
**Numerical (Interval)**:	None detected
**Numerical (Ratio)**: sale price, num bedrooms, num bathrooms, sqft_living, 
sqft_lot, num floors, sqft_above, sqft_basement, yr_built, yr_renovated, date of transaction
```{r}

classify_data_types <- function(df) {
  # Initialize empty lists for each type
  nominal <- c()
  ordinal <- c()
  interval <- c()
  ratio <- c()
  
  for (colname in names(df)) {
    col <- df[[colname]]
    
    # Guessing types
    if (is.character(col) || is.factor(col)) {
      # Factors *might* be ordinal if they have levels with order
      if (is.ordered(col)) {
        ordinal <- c(ordinal, colname)
      } else {
        nominal <- c(nominal, colname)
      }
    } else if (is.numeric(col)) {
      # Assume ratio by default (true zero exists)
      ratio <- c(ratio, colname)
    } else if (inherits(col, "Date") || inherits(col, "POSIXct")) {
      # Dates are often treated as interval or ratio depending on use
      interval <- c(interval, colname)
    } else {
      nominal <- c(nominal, colname)  # fallback
    }
  }
  
  # Create markdown table
  cat("## Data Types of Attributes\n\n")
  cat("| **Data Type** | **Attributes** |\n")
  cat("|---------------|----------------|\n")
  cat(sprintf("| **Nominal** | %s |\n", paste(nominal, collapse = ", ")))
  cat(sprintf("| **Ordinal** | %s |\n", paste(ordinal, collapse = ", ")))
  cat(sprintf("| **Interval** | %s |\n", ifelse(length(interval) > 0, paste(interval, collapse = ", "), "*(None detected)*")))
  cat(sprintf("| **Ratio** | %s |\n", paste(ratio, collapse = ", ")))
}

housing_data$view <- factor(housing_data$view, ordered = TRUE)
housing_data$condition <- factor(housing_data$condition, ordered = TRUE)
housing_data$waterfront <- factor(housing_data$waterfront)  # If 0/1 or Yes/No

classify_data_types(housing_data)

```

# Data Summary & Initial Insights
```{r}
# View first few rows
head(housing_data)
```

```{r}
# Load necessary libraries 
library(tidyverse)
library(naniar)      # For missing data visualization
library(ggcorrplot)  # For correlation plots
library(gridExtra)   # For arranging multiple plots
library(scales)      # For formatting labels
library(knitr)
library(dplyr)

# Read the dataset
# Assuming the CSV file is in the working directory
housing_data <- read.csv("USA Housing Dataset.csv")
```


```{r}
# 1. Basic Structure and Overview
# ----------------------------------
# Display dataset structure
str(housing_data)

# Display first few rows
head(housing_data)

# Basic dimensions
cat("Dataset dimensions:", dim(housing_data)[1], "rows and", dim(housing_data)[2], "columns\n")
```

```{r}
# 2. Summary Statistics
# ---------------------
# Numerical variable summaries
summary(housing_data)

numerical_summary <- housing_data %>%
  select(price, bedrooms, bathrooms, sqft_living, sqft_lot, floors, 
         waterfront, view, condition, sqft_above, sqft_basement, 
         yr_built, yr_renovated) %>%
  summary()

print(numerical_summary)
```

```{r}
# Summary Statistics for Data Type of the Attributes
# --- Define variables by data type ---
nominal_vars <- c("street", "city", "statezip", "country", "waterfront")
ordinal_vars <- c("view", "condition")
ratio_vars <- c("price", "bedrooms", "bathrooms", "sqft_living", "sqft_lot",
                "floors", "sqft_above", "sqft_basement", "yr_built", "yr_renovated")

# --- Helper function to calculate mode ---
get_mode <- function(x) {
  ux <- na.omit(unique(x))
  ux[which.max(tabulate(match(x, ux)))]
}

# --- Summary for Nominal Variables ---
nominal_summary <- housing_data %>%
  select(all_of(nominal_vars)) %>%
  summarise(across(everything(),
                   list(
                     Mode = ~as.character(get_mode(.)),
                     Missing = ~as.character(sum(is.na(.)))
                   )))

# Now pivot â€” no type mismatch since everything is character
nominal_summary_long <- nominal_summary %>%
  pivot_longer(
    everything(),
    names_to = c("Variable", ".value"),
    names_sep = "_"
  )

# Display nicely
kable(nominal_summary_long, caption = "Summary of Nominal Variables (Mode & Missing Count)")

# --- Summary for Ordinal Variables (Frequency counts) ---
ordinal_summary <- lapply(housing_data[ordinal_vars], function(x) as.data.frame(table(x)))
names(ordinal_summary) <- ordinal_vars

# Display each ordinal variable as a separate table
for (var in names(ordinal_summary)) {
  cat("\n\n")
  cat("### Frequencies for Ordinal Variable:", var, "\n")
  print(kable(ordinal_summary[[var]], col.names = c(var, "Frequency")))
}

# --- Summary for Ratio Variables ---
ratio_summary <- housing_data %>%
  select(all_of(ratio_vars)) %>%
  summarise(across(everything(),
                   list(
                     Mean = ~round(mean(., na.rm = TRUE), 2),
                     Median = ~median(., na.rm = TRUE),
                     Min = ~min(., na.rm = TRUE),
                     Max = ~max(., na.rm = TRUE),
                     Range = ~max(., na.rm = TRUE) - min(., na.rm = TRUE),
                     SD = ~round(sd(., na.rm = TRUE), 2),
                     Missing = ~sum(is.na(.))
                   ))) %>%
  pivot_longer(everything(),
               names_to = c("Variable", ".value"),
               names_sep = "_")

kable(ratio_summary, caption = "Summary of Ratio Variables")
```

```{r}
# 3. Missing Value Analysis
# -------------------------
# Check for missing values
missing_values <- colSums(is.na(housing_data))
cat("Missing values per column:\n")
print(missing_values)

# Visualize missing data pattern (if there are missing values)
if(sum(missing_values) > 0) {
  miss_plot <- gg_miss_var(housing_data) + 
    labs(title = "Missing Values by Variable")
  print(miss_plot)
}

# 7. Calculate price per square foot
# ---------------------------------
housing_data$price_per_sqft <- housing_data$price / housing_data$sqft_living

# Get the top 10 cities by count
top_cities <- names(sort(table(housing_data$city), decreasing = TRUE)[1:10])

# Filter for those cities
city_data <- housing_data %>%
  filter(city %in% top_cities)

# Box plot of price per square foot by city
p11 <- ggplot(city_data, aes(x = reorder(city, price_per_sqft, FUN = median), y = price_per_sqft)) +
  geom_boxplot(fill = "lightblue") +
  scale_y_continuous(labels = scales::dollar_format()) +
  labs(title = "Price per Square Foot by City (Top 10 Cities)", 
       x = "City", 
       y = "Price per Square Foot") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

print(p11)
```

# Explanation/Findings from the Box Plot
It helps **visualize the distribution of price per square foot** for the top 10 cities in the dataset. 
It also compares how housing affordability varies across different locations.


**Observations:**

1. There is a clear variability in pricing across cities, with some cities showing much higher median prices.
2. A few cities have wider interquartile ranges and outliers, indicating greater pricing diversity within those areas.
3. Other cities appear more uniform, suggesting consistent pricing per square foot.


```{r}
# 8. Correlation Analysis
# ----------------------
# Create correlation matrix for numerical variables
corr_vars <- housing_data %>%
  select(price, bedrooms, bathrooms, sqft_living, sqft_lot, floors, 
         waterfront, view, condition, sqft_above, sqft_basement, yr_built)

correlation_matrix <- cor(corr_vars, use = "complete.obs")
print(correlation_matrix)

# Visualize correlation matrix
p12 <- ggcorrplot(correlation_matrix, 
                  hc.order = TRUE, 
                  type = "lower", 
                  lab = TRUE, 
                  lab_size = 3,
                  colors = c("#6D9EC1", "white", "#E46726")) +
  labs(title = "Correlation Matrix of Housing Features")

print(p12)

# 9. Outlier Detection
# ------------------
# Calculate z-scores for price
housing_data$price_zscore <- (housing_data$price - mean(housing_data$price)) / sd(housing_data$price)

# Identify outliers (z-score > 3 or < -3)
price_outliers <- housing_data %>%
  filter(abs(price_zscore) > 3) %>%
  select(price, bedrooms, bathrooms, sqft_living, city, price_zscore) %>%
  arrange(desc(price_zscore))

cat("Number of price outliers:", nrow(price_outliers), "\n")
print(head(price_outliers, 10))

# 10. Analyze bedrooms to bathrooms ratio
# -------------------------------------
housing_data$bed_bath_ratio <- housing_data$bedrooms / housing_data$bathrooms

p13 <- ggplot(housing_data, aes(x = bed_bath_ratio)) +
  geom_histogram(fill = "purple", color = "black", bins = 30, alpha = 0.7) +
  labs(title = "Distribution of Bedroom to Bathroom Ratio", 
       x = "Bedrooms/Bathrooms Ratio", 
       y = "Count") +
  theme_minimal()

print(p13)

# 11. Summary of Key Findings
# --------------------------
cat("\n----- KEY FINDINGS FROM EXPLORATORY DATA ANALYSIS -----\n")

# Calculate and print key metrics
average_price <- mean(housing_data$price)
median_price <- median(housing_data$price)
price_range <- max(housing_data$price) - min(housing_data$price)
avg_price_per_sqft <- mean(housing_data$price_per_sqft)
top_price_cities <- housing_data %>%
  group_by(city) %>%
  summarise(avg_price = mean(price),
            count = n()) %>%
  filter(count >= 20) %>%
  arrange(desc(avg_price)) %>%
  head(3)

cat("Average home price: $", formatC(average_price, format="f", digits=2, big.mark=","), "\n")
cat("Median home price: $", formatC(median_price, format="f", digits=2, big.mark=","), "\n")
cat("Price range: $", formatC(price_range, format="f", digits=2, big.mark=","), "\n")
cat("Average price per square foot: $", formatC(avg_price_per_sqft, format="f", digits=2), "\n")
cat("Top 3 most expensive cities (min 20 properties):\n")
print(top_price_cities)

# Calculate strongest correlations with price
price_correlations <- correlation_matrix[1, ]
top_correlated <- sort(abs(price_correlations), decreasing = TRUE)[2:4]
cat("Strongest correlations with price:\n")
for(i in 1:3) {
  var_name <- names(top_correlated)[i]
  corr_value <- price_correlations[var_name]
  cat(var_name, ": ", round(corr_value, 3), "\n")
}

# Print dataset quality assessment
cat("\nDataset Quality Assessment:\n")
cat("- Missing values: ", if(sum(missing_values) == 0) "None" else sum(missing_values), "\n")
cat("- Detected outliers: ", nrow(price_outliers), "\n")
cat("- Most common property type: ", 
    names(which.max(table(housing_data$bedrooms))), 
    "-bedroom homes (", 
    round(max(table(housing_data$bedrooms))/nrow(housing_data)*100, 1), 
    "%)\n", sep="")
```

# Expanding Investment Knowledge
## Additional Data Source: House Price Index (HPI)
Beyond the USA Housing Dataset, incorporating additional data sources can 
significantly enhance investment decision-making. One such dataset is the 
**All-Transactions House Price Index (HPI)** for Washington-Arlington-Alexandria, 
provided by the **Federal Reserve Economic Data (FRED)**: 

**Dataset Link:** [FRED HPI - Washington-Arlington-Alexandria](https://fred.stlouisfed.org/series/ATNHPIUS47894Q)

---

## Why is this dataset useful?
This dataset is valuable because it provides **macroeconomic context** for real 
estate trends. Key benefits include:

1. **Forward-looking indicators** â€“ Helps predict housing market trends based 
on historical price movements.
2. **Regional economic health assessment** â€“ A rising index may indicate a 
strong local economy, while a declining index may suggest potential risks.
3. **Long-term trends analysis** â€“ Unlike transaction-based datasets, this 
allows for a broader understanding of **housing appreciation** over time.

## How does this dataset complement our current data analysis?
While the **USA Housing Dataset** focuses on 
**individual property characteristics and sales prices**, the **HPI dataset** 
provides a **time-series perspective**, allowing us to:

1. **Identify market cycles** â€“ Recognize housing booms and downturns to 
optimize investment timing.
2. **Assess neighborhood growth potential** â€“ Determine which areas are 
experiencing sustained property value appreciation.
3. **Perform risk assessment** â€“ Compare micro-level data (individual home 
sales) with macroeconomic trends to mitigate investment risks.

---

## Integrating the HPI dataset in R
We can retrieve this dataset directly from FRED using the `quantmod` package in R:

```{r}
# Load necessary package
library(quantmod)

# Retrieve the HPI data from FRED
getSymbols("ATNHPIUS47894Q", src = "FRED")

# View the first few rows
head(ATNHPIUS47894Q)

# Plot the data to visualize trends
plot(ATNHPIUS47894Q, 
     main = "All-Transactions House Price Index (Washington-Arlington-Alexandria)",
     col = "blue", lwd = 2,
     ylab = "HPI", xlab = "Year")

```
---
## Why is this plot important?

It shows the **All-Transactions House Price Index (HPI)** for the Washington-Arlington-Alexandria region over time. 

This visualization helps understand how housing prices have changed in this metropolitan area.


**Observations:**
1. There is a steady increase in housing prices over the past few decades, especially after the 2012 recovery
2. There is a noticeable dip around 2008â€“2010, aligning with the U.S. housing market crash during the financial crisis
3. There is a recent rapid growth in prices, likely reflecting the pandemic-era housing demand surge and market inflation

---

